stroke_noNAs_noOL <- stroke_noNAs_noOL[-which(stroke_noNAs_noOL$avg_glucose_level %in% agl_outliers),]
stroke_noNAs_noOL <- stroke_noNAs_noOL[-which(stroke_noNAs_noOL$bmi %in% bmi_outliers),]
# Examine correlations between all Independent Variables
cor(stroke_noNAs_noOL[1:10])
# PCA and normalization
stroke.pca.normdata <- prcomp(stroke_noNAs_noOL, scale = TRUE, center = TRUE)
stroke.pca.normdata$rotation
# Values of normalized data after transformation
head(stroke.pca.normdata$x)
# Visualize PCA to see most important principal components
plot(stroke.pca.normdata, type = "l", main = "With data normalization")
# Elbow point occurs around PC2 (if 1.0 as threshold) or PC8 (if 0.75 as threshold)
# Check correlations of original vs normalized transformed data
# Original
cor(stroke_noNAs_noOL)
# Normalized transformed
cor(stroke.pca.normdata$x)
# Correlations between PCs in normalized transformed data are almost 0 - these PCs are now orthogonal
# Normalize continuous numeric variables
# Such as age, avg_blood_glucose, and bmi
# Using z-score methods
stroke_noNAs_noOL$age <- (stroke_noNAs_noOL$age - mean(stroke_noNAs_noOL$age))/sd(stroke_noNAs_noOL$age)
stroke_noNAs_noOL$avg_glucose_level <- (stroke_noNAs_noOL$avg_glucose_level - mean(stroke_noNAs_noOL$avg_glucose_level))/sd(stroke_noNAs_noOL$avg_glucose_level)
stroke_noNAs_noOL$bmi <- (stroke_noNAs_noOL$bmi - mean(stroke_noNAs_noOL$bmi))/sd(stroke_noNAs_noOL$bmi)
# Split dataset into 70% training, 30% testing sets
stroke_index1 <- sample(1:nrow(stroke_noNAs_noOL), 0.7 * nrow(stroke_noNAs_noOL))
# Assign selected sample as training set
# Assign leftover dataset as test set
train.set1 <- stroke_noNAs_noOL[stroke_index1,]
test.set1 <- stroke_noNAs_noOL[-stroke_index1,]
# Logistic regression model for prediction
glm_model1 <- glm(formula = stroke~., data = train.set1, family = "binomial")
summary(glm_model1)
predicted1 <- predict(glm_model1, test.set1, type = "response")
# Setting 0.5 as threshold - binary prediction
predicted_class1 <- ifelse(predicted1 >= 0.5, "Stroke", "No Stroke")
ConfusionMatrix1 <- table(actual = test.set1$stroke, predicted = predicted_class1)
ConfusionMatrix1
knitr::opts_chunk$set(echo = TRUE)
stroke <- read.csv(file="stroke_1_raw.csv",header=T, sep=",")
# Descriptive analysis
str(stroke)
summary(stroke)
# Convert 'N/A's (strings) in dataset to NA
is.na(stroke) <- stroke == "N/A"
# Count number of NAs in dataset
sum(is.na(stroke))
# Count number of NAs in all columns
colSums(is.na(stroke))
# Count number of 'Unknown's in all columns
colSums(stroke == "Unknown")
# Remove first column 'id'; irrelevant to data analysis
stroke <- stroke[2:12]
# Check attribute levels and convert data types to numeric
# For binary "Yes"/"No" values, "Yes" = 1 and "No" = 2
str(stroke)
unique(stroke$gender)
stroke$gender <- gsub("Male", 1, stroke$gender)
stroke$gender <- gsub("Female", 2, stroke$gender)
stroke$gender <- gsub("Other", 3, stroke$gender)
stroke$gender <- as.numeric(stroke$gender)
unique(stroke$gender)
unique(stroke$ever_married)
stroke$ever_married <- gsub("Yes", 1, stroke$ever_married)
stroke$ever_married <- gsub("No", 0, stroke$ever_married)
stroke$ever_married <- as.numeric(stroke$ever_married)
unique(stroke$ever_married)
unique(stroke$work_type)
stroke$work_type <- gsub("Private", 1, stroke$work_type)
stroke$work_type <- gsub("Self-employed", 2, stroke$work_type)
stroke$work_type <- gsub("Govt_job", 3, stroke$work_type)
stroke$work_type <- gsub("children", 4, stroke$work_type)
stroke$work_type <- gsub("Never_worked", 5, stroke$work_type)
stroke$work_type <- as.numeric(stroke$work_type)
unique(stroke$work_type)
unique(stroke$Residence_type)
stroke$Residence_type <- gsub("Urban", 1, stroke$Residence_type)
stroke$Residence_type <- gsub("Rural", 2, stroke$Residence_type)
stroke$Residence_type <- as.numeric(stroke$Residence_type)
unique(stroke$Residence_type)
stroke$bmi <- as.numeric(stroke$bmi)
unique(stroke$smoking_status)
stroke$smoking_status <- gsub("formerly smoked", 1, stroke$smoking_status)
stroke$smoking_status <- gsub("never smoked", 2, stroke$smoking_status)
stroke$smoking_status <- gsub("smokes", 3, stroke$smoking_status)
stroke$smoking_status <- gsub("Unknown", 4, stroke$smoking_status)
stroke$smoking_status <- as.numeric(stroke$smoking_status)
unique(stroke$smoking_status)
# Assign "No Stroke" and "Stroke" labels for Stroke attribute
stroke$stroke <- ifelse(stroke$stroke == 0, "No Stroke", "Stroke")
# Assign Stroke values as factor levels
stroke$stroke <- as.factor(stroke$stroke)
# Check that all attributes are now numeric data types
str(stroke)
# Deal with NAs
# Method 1: remove NAs
stroke_noNAs <- stroke[complete.cases(stroke), ]
# Method 2: replace NAs with values using k-NN algorithm?
# Deal with outliers
# Box plot to visualize outliers
boxplot(as.matrix(stroke_noNAs[1:10]))
# Excluding categorical variables, avg_glucose_level
# And bmi have several outliers
# Remove outliers using interquartile range values
agl_outliers <- boxplot(stroke$avg_glucose_level, plot = FALSE)$out
bmi_outliers <- boxplot(stroke$bmi, plot = FALSE)$out
stroke_noNAs_noOL <- stroke_noNAs
stroke_noNAs_noOL <- stroke_noNAs_noOL[-which(stroke_noNAs_noOL$avg_glucose_level %in% agl_outliers),]
stroke_noNAs_noOL <- stroke_noNAs_noOL[-which(stroke_noNAs_noOL$bmi %in% bmi_outliers),]
# Examine correlations between all Independent Variables
cor(stroke_noNAs_noOL[1:10])
# Normalize continuous numeric variables
# Such as age, avg_blood_glucose, and bmi
# Using z-score methods
stroke_noNAs_noOL$age <- (stroke_noNAs_noOL$age - mean(stroke_noNAs_noOL$age))/sd(stroke_noNAs_noOL$age)
stroke_noNAs_noOL$avg_glucose_level <- (stroke_noNAs_noOL$avg_glucose_level - mean(stroke_noNAs_noOL$avg_glucose_level))/sd(stroke_noNAs_noOL$avg_glucose_level)
stroke_noNAs_noOL$bmi <- (stroke_noNAs_noOL$bmi - mean(stroke_noNAs_noOL$bmi))/sd(stroke_noNAs_noOL$bmi)
# Split dataset into 70% training, 30% testing sets
stroke_index1 <- sample(1:nrow(stroke_noNAs_noOL), 0.7 * nrow(stroke_noNAs_noOL))
# Assign selected sample as training set
# Assign leftover dataset as test set
train.set1 <- stroke_noNAs_noOL[stroke_index1,]
test.set1 <- stroke_noNAs_noOL[-stroke_index1,]
# Logistic regression model for prediction
glm_model1 <- glm(formula = stroke~., data = train.set1, family = "binomial")
summary(glm_model1)
predicted1 <- predict(glm_model1, test.set1, type = "response")
# Setting 0.5 as threshold - binary prediction
predicted_class1 <- ifelse(predicted1 >= 0.5, "Stroke", "No Stroke")
ConfusionMatrix1 <- table(actual = test.set1$stroke, predicted = predicted_class1)
ConfusionMatrix1
knitr::opts_chunk$set(echo = TRUE)
stroke <- read.csv(file="stroke_1_raw.csv",header=T, sep=",")
# Descriptive analysis
str(stroke)
summary(stroke)
# Convert 'N/A's (strings) in dataset to NA
is.na(stroke) <- stroke == "N/A"
# Count number of NAs in dataset
sum(is.na(stroke))
# Count number of NAs in all columns
colSums(is.na(stroke))
# Count number of 'Unknown's in all columns
colSums(stroke == "Unknown")
# Remove first column 'id'; irrelevant to data analysis
stroke <- stroke[2:12]
# Check attribute levels and convert data types to numeric
# For binary "Yes"/"No" values, "Yes" = 1 and "No" = 2
str(stroke)
unique(stroke$gender)
stroke$gender <- gsub("Male", 1, stroke$gender)
stroke$gender <- gsub("Female", 2, stroke$gender)
stroke$gender <- gsub("Other", 3, stroke$gender)
stroke$gender <- as.numeric(stroke$gender)
unique(stroke$gender)
stroke$bmi <- as.numeric(stroke$bmi)
# Assign "No Stroke" and "Stroke" labels for Stroke attribute
stroke$stroke <- ifelse(stroke$stroke == 0, "No Stroke", "Stroke")
# Assign Stroke values as factor levels
stroke$stroke <- as.factor(stroke$stroke)
# Check that all attributes are now numeric data types
str(stroke)
# Deal with NAs
# Method 1: remove NAs
stroke_noNAs <- stroke[complete.cases(stroke), ]
# Leave outliers as is
# Examine correlations between all Independent Variables
# cor(stroke_noNAs[1:10])
# Normalize continuous numeric variables
# Such as age, avg_blood_glucose, and bmi
# Using z-score methods
stroke_noNAs$age <- (stroke_noNAs$age - mean(stroke_noNAs$age))/sd(stroke_noNAs$age)
stroke_noNAs$avg_glucose_level <- (stroke_noNAs$avg_glucose_level - mean(stroke_noNAs$avg_glucose_level))/sd(stroke_noNAs$avg_glucose_level)
stroke_noNAs$bmi <- (stroke_noNAs$bmi - mean(stroke_noNAs$bmi))/sd(stroke_noNAs$bmi)
# Split dataset into 70% training, 30% testing sets
stroke_index2 <- sample(1:nrow(stroke_noNAs), 0.7 * nrow(stroke_noNAs))
# Assign selected sample as training set
# Assign leftover dataset as test set
train.set2 <- stroke_noNAs[stroke_index2,]
test.set2 <- stroke_noNAs[-stroke_index2,]
# Logistic regression model for prediction
glm_model2 <- glm(formula = stroke~., data = train.set2, family = "binomial")
summary(glm_model2)
predicted2 <- predict(glm_model2, test.set2, type = "response")
# Setting 0.5 as threshold - binary prediction
predicted_class2 <- ifelse(predicted2 >= 0.5, "Stroke", "No Stroke")
ConfusionMatrix2 <- table(actual = test.set2$stroke, predicted = predicted_class2)
ConfusionMatrix2
str(predicted2)
summary(predicted2)
knitr::opts_chunk$set(echo = TRUE)
stroke <- read.csv(file="stroke_1_raw.csv",header=T, sep=",")
# Descriptive analysis
str(stroke)
summary(stroke)
# Convert 'N/A's (strings) in dataset to NA
is.na(stroke) <- stroke == "N/A"
# Count number of NAs in dataset
sum(is.na(stroke))
# Count number of NAs in all columns
colSums(is.na(stroke))
# Count number of 'Unknown's in all columns
colSums(stroke == "Unknown")
# Remove first column 'id'; irrelevant to data analysis
stroke <- stroke[2:12]
# Check attribute levels and convert data types to numeric
# For binary "Yes"/"No" values, "Yes" = 1 and "No" = 2
str(stroke)
unique(stroke$gender)
stroke$gender <- gsub("Male", 1, stroke$gender)
stroke$gender <- gsub("Female", 2, stroke$gender)
stroke$gender <- gsub("Other", 3, stroke$gender)
stroke$gender <- as.numeric(stroke$gender)
unique(stroke$gender)
unique(stroke$ever_married)
stroke$ever_married <- gsub("Yes", 1, stroke$ever_married)
stroke$ever_married <- gsub("No", 0, stroke$ever_married)
stroke$ever_married <- as.numeric(stroke$ever_married)
unique(stroke$ever_married)
unique(stroke$work_type)
stroke$work_type <- gsub("Private", 1, stroke$work_type)
stroke$work_type <- gsub("Self-employed", 2, stroke$work_type)
stroke$work_type <- gsub("Govt_job", 3, stroke$work_type)
stroke$work_type <- gsub("children", 4, stroke$work_type)
stroke$work_type <- gsub("Never_worked", 5, stroke$work_type)
stroke$work_type <- as.numeric(stroke$work_type)
unique(stroke$work_type)
unique(stroke$Residence_type)
stroke$Residence_type <- gsub("Urban", 1, stroke$Residence_type)
stroke$Residence_type <- gsub("Rural", 2, stroke$Residence_type)
stroke$Residence_type <- as.numeric(stroke$Residence_type)
unique(stroke$Residence_type)
stroke$bmi <- as.numeric(stroke$bmi)
unique(stroke$smoking_status)
stroke$smoking_status <- gsub("formerly smoked", 1, stroke$smoking_status)
stroke$smoking_status <- gsub("never smoked", 2, stroke$smoking_status)
stroke$smoking_status <- gsub("smokes", 3, stroke$smoking_status)
stroke$smoking_status <- gsub("Unknown", 4, stroke$smoking_status)
stroke$smoking_status <- as.numeric(stroke$smoking_status)
unique(stroke$smoking_status)
# Check that all attributes are now numeric data types
str(stroke)
# Deal with NAs
# Method 1: remove NAs
stroke_noNAs <- stroke[complete.cases(stroke), ]
# Deal with outliers
# Box plot to visualize outliers
boxplot(as.matrix(stroke_noNAs[1:10]))
# Excluding categorical variables, avg_glucose_level
# And bmi have several outliers
# Remove outliers using interquartile range values
agl_outliers <- boxplot(stroke$avg_glucose_level, plot = FALSE)$out
bmi_outliers <- boxplot(stroke$bmi, plot = FALSE)$out
stroke_noNAs_noOL <- stroke_noNAs
stroke_noNAs_noOL <- stroke_noNAs_noOL[-which(stroke_noNAs_noOL$avg_glucose_level %in% agl_outliers),]
stroke_noNAs_noOL <- stroke_noNAs_noOL[-which(stroke_noNAs_noOL$bmi %in% bmi_outliers),]
# Examine correlations between all Independent Variables
cor(stroke_noNAs_noOL[1:10])
# PCA and normalization
stroke.pca.normdata <- prcomp(stroke_noNAs_noOL, scale = TRUE, center = TRUE)
stroke.pca.normdata$rotation
# Values of normalized data after transformation
head(stroke.pca.normdata$x)
# Visualize PCA to see most important principal components
plot(stroke.pca.normdata, type = "l", main = "With data normalization")
# Elbow point occurs around PC2 (if 1.0 as threshold) or PC8 (if 0.75 as threshold)
# Check correlations of original vs normalized transformed data
# Original
cor(stroke_noNAs_noOL)
# Normalized transformed
cor(stroke.pca.normdata$x)
# Correlations between PCs in normalized transformed data are almost 0 - these PCs are now orthogonal
# Normalize continuous numeric variables
# Such as age, avg_blood_glucose, and bmi
# Using z-score methods
stroke_noNAs_noOL$age <- (stroke_noNAs_noOL$age - mean(stroke_noNAs_noOL$age))/sd(stroke_noNAs_noOL$age)
stroke_noNAs_noOL$avg_glucose_level <- (stroke_noNAs_noOL$avg_glucose_level - mean(stroke_noNAs_noOL$avg_glucose_level))/sd(stroke_noNAs_noOL$avg_glucose_level)
stroke_noNAs_noOL$bmi <- (stroke_noNAs_noOL$bmi - mean(stroke_noNAs_noOL$bmi))/sd(stroke_noNAs_noOL$bmi)
# Split dataset into 70% training, 30% testing sets
stroke_index1 <- sample(1:nrow(stroke_noNAs_noOL), 0.7 * nrow(stroke_noNAs_noOL))
# Assign selected sample as training set
# Assign leftover dataset as test set
train.set1 <- stroke_noNAs_noOL[stroke_index1,]
test.set1 <- stroke_noNAs_noOL[-stroke_index1,]
# Logistic regression model for prediction
glm_model1 <- glm(formula = stroke~., data = train.set1, family = "binomial")
summary(glm_model1)
predicted1 <- predict(glm_model1, test.set1, type = "response")
# Setting 0.5 as threshold - binary prediction
predicted_class1 <- ifelse(predicted1 >= 0.5, "Stroke", "No Stroke")
ConfusionMatrix1 <- table(actual = test.set1$stroke, predicted = predicted_class1)
ConfusionMatrix1
knitr::opts_chunk$set(echo = TRUE)
stroke <- read.csv(file="stroke_1_raw.csv",header=T, sep=",")
# Descriptive analysis
str(stroke)
summary(stroke)
# Convert 'N/A's (strings) in dataset to NA
is.na(stroke) <- stroke == "N/A"
# Count number of NAs in dataset
sum(is.na(stroke))
# Count number of NAs in all columns
colSums(is.na(stroke))
# Count number of 'Unknown's in all columns
colSums(stroke == "Unknown")
# Remove first column 'id'; irrelevant to data analysis
stroke <- stroke[2:12]
# Check attribute levels and convert data types to numeric
# For binary "Yes"/"No" values, "Yes" = 1 and "No" = 2
str(stroke)
unique(stroke$gender)
stroke$gender <- gsub("Male", 1, stroke$gender)
stroke$gender <- gsub("Female", 2, stroke$gender)
stroke$gender <- gsub("Other", 3, stroke$gender)
stroke$gender <- as.numeric(stroke$gender)
unique(stroke$gender)
unique(stroke$ever_married)
stroke$ever_married <- gsub("Yes", 1, stroke$ever_married)
stroke$ever_married <- gsub("No", 0, stroke$ever_married)
stroke$ever_married <- as.numeric(stroke$ever_married)
unique(stroke$ever_married)
unique(stroke$work_type)
stroke$work_type <- gsub("Private", 1, stroke$work_type)
stroke$work_type <- gsub("Self-employed", 2, stroke$work_type)
stroke$work_type <- gsub("Govt_job", 3, stroke$work_type)
stroke$work_type <- gsub("children", 4, stroke$work_type)
stroke$work_type <- gsub("Never_worked", 5, stroke$work_type)
stroke$work_type <- as.numeric(stroke$work_type)
unique(stroke$work_type)
unique(stroke$Residence_type)
stroke$Residence_type <- gsub("Urban", 1, stroke$Residence_type)
stroke$Residence_type <- gsub("Rural", 2, stroke$Residence_type)
stroke$Residence_type <- as.numeric(stroke$Residence_type)
unique(stroke$Residence_type)
stroke$bmi <- as.numeric(stroke$bmi)
unique(stroke$smoking_status)
stroke$smoking_status <- gsub("formerly smoked", 1, stroke$smoking_status)
stroke$smoking_status <- gsub("never smoked", 2, stroke$smoking_status)
stroke$smoking_status <- gsub("smokes", 3, stroke$smoking_status)
stroke$smoking_status <- gsub("Unknown", 4, stroke$smoking_status)
stroke$smoking_status <- as.numeric(stroke$smoking_status)
unique(stroke$smoking_status)
# Assign "No Stroke" and "Stroke" labels for Stroke attribute
# stroke$stroke <- ifelse(stroke$stroke == 0, "No Stroke", "Stroke")
# Assign Stroke values as factor levels
# stroke$stroke <- as.factor(stroke$stroke)
# Check that all attributes are now numeric data types
str(stroke)
# Deal with NAs
# Method 1: remove NAs
stroke_noNAs <- stroke[complete.cases(stroke), ]
# Method 2: replace NAs with values using k-NN algorithm?
# Deal with outliers
# Did not remove outliers
# Examine correlations between all Independent Variables
cor(stroke_noNAs[1:10])
# PCA and normalization
stroke.pca.normdata <- prcomp(stroke_noNAs, scale = TRUE, center = TRUE)
stroke.pca.normdata$rotation
# Values of normalized data after transformation
head(stroke.pca.normdata$x)
# Visualize PCA to see most important principal components
plot(stroke.pca.normdata, type = "l", main = "With data normalization")
# Elbow point occurs around PC3 (if 1.0 as threshold), so PC1 and PC2 explain most of the variance in the data
# Check correlations of original vs normalized transformed data
# Original
cor(stroke_noNAs)
# Normalized transformed
cor(stroke.pca.normdata$x)
# Correlations between PCs in normalized transformed data are almost 0 - these PCs are now orthogonal
# Normalize continuous numeric variables
# Such as age, avg_blood_glucose, and bmi
# Using z-score methods
stroke_noNAs$age <- (stroke_noNAs$age - mean(stroke_noNAs$age))/sd(stroke_noNAs$age)
stroke_noNAs$avg_glucose_level <- (stroke_noNAs$avg_glucose_level - mean(stroke_noNAs$avg_glucose_level))/sd(stroke_noNAs$avg_glucose_level)
stroke_noNAs$bmi <- (stroke_noNAs$bmi - mean(stroke_noNAs$bmi))/sd(stroke_noNAs$bmi)
# Split dataset into 70% training, 30% testing sets
stroke_index1 <- sample(1:nrow(stroke_noNAs), 0.7 * nrow(stroke_noNAs))
# Assign selected sample as training set
# Assign leftover dataset as test set
train.set1 <- stroke_noNAs[stroke_index1,]
test.set1 <- stroke_noNAs[-stroke_index1,]
# Logistic regression model for prediction
glm_model1 <- glm(formula = stroke~., data = train.set1, family = "binomial")
summary(glm_model1)
predicted1 <- predict(glm_model1, test.set1, type = "response")
# Setting 0.5 as threshold - binary prediction
predicted_class1 <- ifelse(predicted1 >= 0.5, "Stroke", "No Stroke")
ConfusionMatrix1 <- table(actual = test.set1$stroke, predicted = predicted_class1)
ConfusionMatrix1
knitr::opts_chunk$set(echo = TRUE)
#install.packages("RCurl")
#install.packages("MASS")
#install.packages("leaps")
library(RCurl)
library(MASS)
library(leaps)
stroke <- read.csv(file="stroke_1_raw.csv",header=T, sep=",")
# Descriptive analysis
str(stroke)
summary(stroke)
# Convert 'N/A's (strings) in dataset to NA
is.na(stroke) <- stroke == "N/A"
# Count number of NAs in dataset
sum(is.na(stroke))
# Count number of NAs in all columns
colSums(is.na(stroke))
# Count number of 'Unknown's in all columns
colSums(stroke == "Unknown")
# Remove first column 'id'; irrelevant to data analysis
stroke <- stroke[2:12]
# Check attribute levels and convert data types to numeric
# For binary "Yes"/"No" values, "Yes" = 1 and "No" = 2
str(stroke)
unique(stroke$gender)
stroke$gender <- gsub("Male", 1, stroke$gender)
stroke$gender <- gsub("Female", 2, stroke$gender)
stroke$gender <- gsub("Other", 3, stroke$gender)
stroke$gender <- as.numeric(stroke$gender)
unique(stroke$gender)
unique(stroke$ever_married)
stroke$ever_married <- gsub("Yes", 1, stroke$ever_married)
stroke$ever_married <- gsub("No", 0, stroke$ever_married)
stroke$ever_married <- as.numeric(stroke$ever_married)
unique(stroke$ever_married)
unique(stroke$work_type)
stroke$work_type <- gsub("Private", 1, stroke$work_type)
stroke$work_type <- gsub("Self-employed", 2, stroke$work_type)
stroke$work_type <- gsub("Govt_job", 3, stroke$work_type)
stroke$work_type <- gsub("children", 4, stroke$work_type)
stroke$work_type <- gsub("Never_worked", 5, stroke$work_type)
stroke$work_type <- as.numeric(stroke$work_type)
unique(stroke$work_type)
unique(stroke$Residence_type)
stroke$Residence_type <- gsub("Urban", 1, stroke$Residence_type)
stroke$Residence_type <- gsub("Rural", 2, stroke$Residence_type)
stroke$Residence_type <- as.numeric(stroke$Residence_type)
unique(stroke$Residence_type)
stroke$bmi <- as.numeric(stroke$bmi)
unique(stroke$smoking_status)
stroke$smoking_status <- gsub("formerly smoked", 1, stroke$smoking_status)
stroke$smoking_status <- gsub("never smoked", 2, stroke$smoking_status)
stroke$smoking_status <- gsub("smokes", 3, stroke$smoking_status)
stroke$smoking_status <- gsub("Unknown", 4, stroke$smoking_status)
stroke$smoking_status <- as.numeric(stroke$smoking_status)
unique(stroke$smoking_status)
# Check that all attributes are now numeric data types
str(stroke)
# Deal with NAs
# Method 1: remove NAs
stroke_noNAs <- stroke[complete.cases(stroke), ]
# Deal with outliers
# Did not remove outliers
# Examine correlations between all Independent Variables
cor(stroke_noNAs[1:10])
# Feature selection - see best combo of attributes
subsets <- regsubsets(stroke~gender+age+hypertension+heart_disease+ever_married+work_type+Residence_type+avg_glucose_level+bmi+smoking_status, data = stroke_noNAs, nbest = 1)
sub.sum <- summary(subsets)
as.data.frame(sub.sum$outmat)
# In order of importance:
# age (8x*), avg_glucose_level (7x*), heart_disease (6x*), hypertension(5x*), ever_married (4x*), bmi (3x*), work_type (2x*), smoking_status (1x*)
# Normalize continuous numeric variables
# Such as age, avg_blood_glucose, and bmi
# Using z-score methods
stroke_noNAs$age <- (stroke_noNAs$age - mean(stroke_noNAs$age))/sd(stroke_noNAs$age)
stroke_noNAs$avg_glucose_level <- (stroke_noNAs$avg_glucose_level - mean(stroke_noNAs$avg_glucose_level))/sd(stroke_noNAs$avg_glucose_level)
stroke_noNAs$bmi <- (stroke_noNAs$bmi - mean(stroke_noNAs$bmi))/sd(stroke_noNAs$bmi)
# Split dataset into 70% training, 30% testing sets
stroke_index1 <- sample(1:nrow(stroke_noNAs), 0.7 * nrow(stroke_noNAs))
# Assign selected sample as training set
# Assign leftover dataset as test set
train.set1 <- stroke_noNAs[stroke_index1,]
test.set1 <- stroke_noNAs[-stroke_index1,]
# Logistic regression model for prediction
# Using only the top 4 features based on feature selection: age, avg_glucose_level, heart_disease, hypertension
glm_model1 <- glm(formula = stroke~age+avg_glucose_level+heart_disease+hypertension, data = train.set1, family = "binomial")
summary(glm_model1)
predicted1 <- predict(glm_model1, test.set1, type = "response")
# Setting 0.5 as threshold - binary prediction
predicted_class1 <- ifelse(predicted1 >= 0.5, "Stroke", "No Stroke")
ConfusionMatrix1 <- table(actual = test.set1$stroke, predicted = predicted_class1)
ConfusionMatrix1
# Convert original raw csv dataset into a dataset that
# Can be uploaded to http://ikuz.eu/csv2arff/ for conversion
# Into arff file, to be then used in Python code.
# This requires 'N/A' string values to be replaced with
# Placeholder value. Since max numeric value of BMI is 97.60
# I have selected my placeholder value to replace NAs as
# the number 5000.
# Read dataset
stroke <- read.csv(file="stroke_1_raw.csv",header=T, sep=",")
# Descriptive analysis
str(stroke)
summary(stroke)
# Convert 'N/A's (strings) in dataset to NA
is.na(stroke) <- stroke == "N/A"
# Count number of NAs in dataset
sum(is.na(stroke))
# Count number of NAs in all columns
colSums(is.na(stroke))
# Convert bmi data type into numeric and check conversion
stroke$bmi <- as.numeric(stroke$bmi)
str(stroke)
summary(stroke) # Can see that max bmi value is 97.60
# Replace all NAs with 5000 as placeholder value
# This will be subsequently converted back as NA value in
# Python code
stroke[is.na(stroke)] <- 5000
# Count how many 5000 values are in dataset (should be 201)
sum(stroke==5000)
# Save the NA-converted-to-5000 file as preprocessed dataset
write.csv(stroke, "C:\\Users\\Diane\\Documents\\Ryerson\\Data Analytics Cert\\6. CIND820 - Big Data Analytics Project\\CIND820_Stroke_Project\\stroke preprocessed.csv", row.names = TRUE)
