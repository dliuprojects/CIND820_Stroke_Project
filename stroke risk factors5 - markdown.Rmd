---
title: "Stroke Factors: Classification & Predictive Analytics"
author: "Danyang Liu (500936348). Supervisor: Dr. Ceni Babaoglu"
date: "3/7/2022"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
#install.packages("RCurl")
#install.packages("MASS")
#install.packages("leaps")

library(RCurl)
library(MASS)
library(leaps)
```

### Dataset: removed NAs, keep outliers
### Converted cat variables into num
### Using feature selection to narrow down variables

### Read dataset

```{r}
stroke <- read.csv(file="stroke_1_raw.csv",header=T, sep=",")
```


### Exploratory Analytics and Data Cleaning

```{r}
# Descriptive analysis
str(stroke)
summary(stroke)

# Convert 'N/A's (strings) in dataset to NA
is.na(stroke) <- stroke == "N/A"
# Count number of NAs in dataset
sum(is.na(stroke))
# Count number of NAs in all columns
colSums(is.na(stroke))

# Count number of 'Unknown's in all columns
colSums(stroke == "Unknown")

# Remove first column 'id'; irrelevant to data analysis
stroke <- stroke[2:12]

# Check attribute levels and convert data types to numeric
# For binary "Yes"/"No" values, "Yes" = 1 and "No" = 2
str(stroke)

unique(stroke$gender)
stroke$gender <- gsub("Male", 1, stroke$gender)
stroke$gender <- gsub("Female", 2, stroke$gender)
stroke$gender <- gsub("Other", 3, stroke$gender)
stroke$gender <- as.numeric(stroke$gender)
unique(stroke$gender)

unique(stroke$ever_married)
stroke$ever_married <- gsub("Yes", 1, stroke$ever_married)
stroke$ever_married <- gsub("No", 0, stroke$ever_married)
stroke$ever_married <- as.numeric(stroke$ever_married)
unique(stroke$ever_married)

unique(stroke$work_type)
stroke$work_type <- gsub("Private", 1, stroke$work_type)
stroke$work_type <- gsub("Self-employed", 2, stroke$work_type)
stroke$work_type <- gsub("Govt_job", 3, stroke$work_type)
stroke$work_type <- gsub("children", 4, stroke$work_type)
stroke$work_type <- gsub("Never_worked", 5, stroke$work_type)
stroke$work_type <- as.numeric(stroke$work_type)
unique(stroke$work_type)

unique(stroke$Residence_type)
stroke$Residence_type <- gsub("Urban", 1, stroke$Residence_type)
stroke$Residence_type <- gsub("Rural", 2, stroke$Residence_type)
stroke$Residence_type <- as.numeric(stroke$Residence_type)
unique(stroke$Residence_type)

stroke$bmi <- as.numeric(stroke$bmi)

unique(stroke$smoking_status)
stroke$smoking_status <- gsub("formerly smoked", 1, stroke$smoking_status)
stroke$smoking_status <- gsub("never smoked", 2, stroke$smoking_status)
stroke$smoking_status <- gsub("smokes", 3, stroke$smoking_status)
stroke$smoking_status <- gsub("Unknown", 4, stroke$smoking_status)
stroke$smoking_status <- as.numeric(stroke$smoking_status)
unique(stroke$smoking_status)

# Check that all attributes are now numeric data types
str(stroke)

# Deal with NAs
# Method 1: remove NAs
stroke_noNAs <- stroke[complete.cases(stroke), ]

# Deal with outliers
# Did not remove outliers

# Examine correlations between all Independent Variables
cor(stroke_noNAs[1:10])
```

### Dimensionality Reduction

```{r}
# Feature selection - see best combo of attributes
subsets <- regsubsets(stroke~gender+age+hypertension+heart_disease+ever_married+work_type+Residence_type+avg_glucose_level+bmi+smoking_status, data = stroke_noNAs, nbest = 1)
sub.sum <- summary(subsets)
as.data.frame(sub.sum$outmat)

# In order of importance:
# age (8x*), avg_glucose_level (7x*), heart_disease (6x*), hypertension(5x*), ever_married (4x*), bmi (3x*), work_type (2x*), smoking_status (1x*)
```

```{r}
# Normalize continuous numeric variables
# Such as age, avg_blood_glucose, and bmi
# Using z-score methods
stroke_noNAs$age <- (stroke_noNAs$age - mean(stroke_noNAs$age))/sd(stroke_noNAs$age)
stroke_noNAs$avg_glucose_level <- (stroke_noNAs$avg_glucose_level - mean(stroke_noNAs$avg_glucose_level))/sd(stroke_noNAs$avg_glucose_level)
stroke_noNAs$bmi <- (stroke_noNAs$bmi - mean(stroke_noNAs$bmi))/sd(stroke_noNAs$bmi)
```


### Classification



### Predictive Analytics: Logistic Regression

```{r}
# Split dataset into 70% training, 30% testing sets
stroke_index1 <- sample(1:nrow(stroke_noNAs), 0.7 * nrow(stroke_noNAs))

# Assign selected sample as training set
# Assign leftover dataset as test set
train.set1 <- stroke_noNAs[stroke_index1,]
test.set1 <- stroke_noNAs[-stroke_index1,]

# Logistic regression model for prediction
# Using only the top 4 features based on feature selection: age, avg_glucose_level, heart_disease, hypertension
glm_model1 <- glm(formula = stroke~age+avg_glucose_level+heart_disease+hypertension, data = train.set1, family = "binomial")
summary(glm_model1)
```


### Evaluation Metrics

```{r}
predicted1 <- predict(glm_model1, test.set1, type = "response")
# Setting 0.5 as threshold - binary prediction
predicted_class1 <- ifelse(predicted1 >= 0.5, "Stroke", "No Stroke")
ConfusionMatrix1 <- table(actual = test.set1$stroke, predicted = predicted_class1)
ConfusionMatrix1

```

### Abysmal predictions using only feature selection and logistic regression applied to dataset with NAs removed (from BMI column) and outliers retained. No strokes are predicted at all